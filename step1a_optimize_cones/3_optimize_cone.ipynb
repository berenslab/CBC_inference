{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference for the Cone\n",
    "\n",
    "- [Define Target and Stimulus](#Target-and-Stimulus)\n",
    "- [Create the cone model](#Cell)\n",
    "- [Select loss function and parameters](#Optimizer)\n",
    "- [Run inference](#Inference)\n",
    "- Plots inference results:\n",
    "    - [Plot results](#Plot-results)\n",
    "    - [Posterior](#Posterior)\n",
    "    - [Best sample(s)](#Best-sample(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select mode: full_inference  / load_only / test\n",
    "\n",
    "- *full_inference*\n",
    "    - Runs the whole inference.\n",
    "    - Takes a long time\n",
    "- *load_only*\n",
    "    - Will not generate new samples, but loads the data generated for the paper.\n",
    "- *test*\n",
    "    - Runs the whole inference, but with fewer samples.\n",
    "    - Illustrates how the inference works, without spending to much CPU power and time.\n",
    "    - However, it might lead to problems, because too few samples are generated leading to bad inference.\n",
    "    - Don't use these results in subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference_mode = 'test'\n",
    "#inference_mode = 'full_inference'\n",
    "inference_mode = 'load_only'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pythoncodepath = os.path.abspath(os.path.join('..', 'pythoncode'))\n",
    "sys.path = [pythoncodepath] + sys.path\n",
    "import importhelper\n",
    "importhelper.addfolders2path(pythoncodepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target and Stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predur = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_t_rng = (1, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experimental data\n",
    "data_folder = os.path.join('..', 'step0_preprocess_iGluSnFR_data', 'data_preprocessed')\n",
    "target_dF_F = pd.read_csv(os.path.join(data_folder, 'ConeData_ReleaseMeanData.csv'))\n",
    "stimulus    = pd.read_csv(os.path.join(data_folder, 'ConeData_stimulus_time_and_amp_corrected.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1,figsize=(12,4),subplot_kw=dict(xlim=stim_t_rng))\n",
    "stimulus.plot(x='Time', ax=axs[0])\n",
    "target_dF_F.plot(x='Time', ax=axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_default = data_utils.load_var(os.path.join('cell_params', 'cone_cell_params_default.pkl'))\n",
    "params_unit = data_utils.load_var(os.path.join('cell_params', 'cone_cell_params_unit.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import retsim_cells\n",
    "importlib.reload(retsim_cells)\n",
    "\n",
    "# Create cell.\n",
    "cell = retsim_cells.Cone(\n",
    "    predur=predur, t_rng=(1.9,2.2),\n",
    "    params_default=params_default, params_unit=params_unit,\n",
    "    stimulus=stimulus, stim_type='Light',\n",
    "    cone_densfile       = 'dens_cone_optimize_cone.n',\n",
    "    nval_file           = 'nval_cone_optimize_cone.n',\n",
    "    chanparams_file     = 'chanparams_cone_optimize_cone.n',\n",
    "    expt_file_list      = ['optimize_cones'],\n",
    "    expt_base_file_list = [os.path.join('retsim_files', 'expt_optimize_cones.cc')],\n",
    "    retsim_path=os.path.abspath(os.path.join('..', 'neuronc', 'models', 'retsim')) + '/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell.create_retsim_expt_file(verbose=False) # Create c++ file.\n",
    "!(cd {cell.retsim_path} && make) # Compile c++ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell.init_retsim(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "\n",
    "Skip this step if you trust the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell.rec_type = 'test'\n",
    "%time rec_data, rec_time, rec_stim = cell.run(plot=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test number of compartements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Should be the same')\n",
    "for c_rm in [1, 10, 20, 40, 100]:\n",
    "    cell.init_retsim(sim_params={'c_rm': c_rm})\n",
    "    print('\\t',cell.comp_data['dia'].values)\n",
    "\n",
    "for c_ri in [1, 100, 200]:\n",
    "    cell.init_retsim(sim_params={'c_ri': c_ri})\n",
    "    print('\\t',cell.comp_data['dia'].values)\n",
    "    \n",
    "print('Should be the same size')\n",
    "for c_cm in [0.9, 1, 2]:\n",
    "    cell.init_retsim(sim_params={'c_cm': c_cm})\n",
    "    print('\\t',cell.comp_data['dia'].values)\n",
    "    \n",
    "print('Should not be the same')\n",
    "for cpl_axon in [0.002, 1]:\n",
    "    cell.init_retsim(sim_params={'cpl_axon': cpl_axon})\n",
    "    print('\\t',cell.comp_data['dia'].values)\n",
    "    \n",
    "cell.init_retsim()\n",
    "print('Default:')\n",
    "print('\\t',cell.comp_data['dia'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test parameters in model\n",
    "\n",
    "Note that channels might not have an influence for the given voltage range (e.g. if the stay below threshold).\n",
    "Also effect might be small for some parameters, maybe they become more important when other parameters changes the overall dynamics, so don't discard them if you don't know yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import retsim_params_test\n",
    "importlib.reload(retsim_params_test);\n",
    "\n",
    "cell.update_t_rng((1.95, 2.15))\n",
    "cell.rec_type = 'optimize'\n",
    "\n",
    "all_equal_params, all_close_params = retsim_params_test.test_if_params_are_used(\n",
    "    cell=cell, params=params_default, Vm_name='Vm Soma', rate_name='rate Cone'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(all_equal_params) == 0\n",
    "assert len(all_close_params) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if inference_mode == 'load_only':\n",
    "    output_folder = 'optimize_cone_submission2'\n",
    "elif inference_mode in ['test', 'full_inference']:\n",
    "    output_folder = 'optimize_cone'\n",
    "else:\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "print('Inference:', inference_mode, '--> Folder:', output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load optimize paramters.\n",
    "opt_params_default = data_utils.load_var(os.path.join('cell_params', 'cone_opt_params_default.pkl'))\n",
    "opt_params_range   = data_utils.load_var(os.path.join('cell_params', 'cone_opt_params_range.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import param_funcs\n",
    "importlib.reload(param_funcs);\n",
    "\n",
    "params = param_funcs.Parameters(p_range=opt_params_range, p_default=opt_params_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optim_funcs\n",
    "importlib.reload(optim_funcs)\n",
    "\n",
    "cell.predur = predur\n",
    "\n",
    "optim = optim_funcs.Optimizer(\n",
    "    cell=cell, params=params, t_rng=stim_t_rng, output_folder=output_folder,\n",
    "    raw_data_labels       = ['rate Cone', 'Vm Soma'],\n",
    "    raw2model_data_labels = {'rate Cone': 'rate', 'Vm Soma': 'Vm'},\n",
    ")\n",
    "\n",
    "%time optim.init_rec_data(allow_loading=True, force_loading=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loss_funcs\n",
    "importlib.reload(loss_funcs);\n",
    "\n",
    "loss = loss_funcs.LossOptimizeCell(\n",
    "    target=target_dF_F, rec_time=optim.get_rec_time(), t_drop=0.5+optim.get_t_rng()[0],\n",
    "    loss_params='Cone eq and range', absolute=False, mode='gauss'\n",
    ")\n",
    "optim.loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.plot_loss_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_output = loss.calc_loss(optim.rec_data['Data'], plot=True, verbose=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TruncatedNormal import TruncatedNormal\n",
    "\n",
    "lower = np.zeros(len(params.p_names))\n",
    "upper = np.ones(len(params.p_names))\n",
    "\n",
    "mean  = [optim.params.sim_param2opt_param(opt_params_default[param], param) for param in params.p_names]\n",
    "std   = [0.3                                                                for param in params.p_names]\n",
    "\n",
    "prior = TruncatedNormal(m=np.array(mean), S=np.diag(np.array(std)**2), lower=lower, upper=upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_sampling_dists\n",
    "\n",
    "PP = plot_sampling_dists.SamplingDistPlotter(\n",
    "    params=params, prior=prior, posterior_list=[],\n",
    "    lbs=np.full(params.p_N, -0.5), ubs=np.full(params.p_N, 1.5)\n",
    ")\n",
    "PP.plot_sampling_dists_1D(plot_peak_lines=False, figsize=(12,8), opt_x=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save optimization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_utils.save_var(opt_params_default, os.path.join('optim_data', output_folder, 'opt_params_default.pkl'))\n",
    "data_utils.save_var(opt_params_range, os.path.join('optim_data', output_folder, 'opt_params_range.pkl'))\n",
    "data_utils.save_var(loss, os.path.join('optim_data', optim.output_folder, 'loss.pkl'))\n",
    "data_utils.save_var(params, os.path.join('optim_data', optim.output_folder, 'params.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "\n",
    "import gpu_test\n",
    "assert gpu_test.run(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_obs_dim = np.argmax(list(optim.model_output2dict({}, 0, rec_data=optim.rec_data['Data'])['loss'].keys()) =='iGluSnFR')\n",
    "print(pseudo_obs_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if inference_mode=='test':\n",
    "    n_samples_per_round = 40\n",
    "    max_rounds = 2\n",
    "    gen_minibatch = 20\n",
    "    print('WARNING: Test mode selected. Results will differ from paper data!')\n",
    "else:\n",
    "    n_samples_per_round = 2000\n",
    "    max_rounds = 4\n",
    "    gen_minibatch = 200\n",
    "    \n",
    "print(n_samples_per_round, '*', max_rounds, 'samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import delfi_funcs\n",
    "\n",
    "delfi_optim = delfi_funcs.DELFI_Optimizer(\n",
    "    optim=optim, prior=prior, n_parallel=30,\n",
    "    gen_minibatch=gen_minibatch, scalar_loss=False,\n",
    "    post_as_truncated_normal=True,\n",
    ")\n",
    "\n",
    "if not(inference_mode=='load_only'):\n",
    "    delfi_optim.init_SNPE(\n",
    "        verbose                 = False,\n",
    "        pseudo_obs_dim          = pseudo_obs_dim,\n",
    "        pseudo_obs_n            = 1,\n",
    "        kernel_bandwidth        = 0.25,\n",
    "        kernel_bandwidth_perc   = 20,\n",
    "        pseudo_obs_use_all_data = False,\n",
    "        n_components            = 1,\n",
    "    )\n",
    "\n",
    "    delfi_optim.run_SNPE(\n",
    "        max_duration_minutes  = 60*24,\n",
    "        max_rounds            = max_rounds,\n",
    "        n_samples_per_round   = n_samples_per_round,\n",
    "        continue_optimization = continue_optimization,\n",
    "        load_init_tds         = load_init_tds,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds                  = data_utils.load_var(os.path.join(delfi_optim.snpe_folder, 'tds.pkl'))\n",
    "inf_snpes            = data_utils.load_var(os.path.join(delfi_optim.snpe_folder, 'inf_snpes.pkl'))\n",
    "sample_distributions = data_utils.load_var(os.path.join(delfi_optim.snpe_folder, 'sample_distributions.pkl'))\n",
    "logs                 = data_utils.load_var(os.path.join(delfi_optim.snpe_folder, 'logs.pkl'))\n",
    "pseudo_obs           = data_utils.load_var(os.path.join(delfi_optim.snpe_folder, 'pseudo_obs.pkl'))\n",
    "kernel_bandwidths    = data_utils.load_var(os.path.join(delfi_optim.snpe_folder, 'kernel_bandwidths.pkl'))\n",
    "\n",
    "# Split prior and posteriors.\n",
    "prior = sample_distributions[0]\n",
    "posteriors = sample_distributions[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, n_samples, d_sort_index = delfi_optim.load_samples(\n",
    "    concat_traces=True, list_traces=False, return_sort_idx=True,\n",
    "    return_n_samples=True, verbose=True\n",
    ")\n",
    "\n",
    "d_min_idx = d_sort_index[0]\n",
    "print('\\nd_min = {:.5f}'.format(samples['loss']['total'][d_min_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_obs_and_bw\n",
    "\n",
    "plot_obs_and_bw.plot(\n",
    "    [pseudo_obs_i[0,pseudo_obs_dim] for pseudo_obs_i in pseudo_obs],\n",
    "    [kernel_bandwidth_i[pseudo_obs_dim] for kernel_bandwidth_i in kernel_bandwidths],\n",
    ")\n",
    "plot_obs_and_bw.plot_logs(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_iws\n",
    "plot_iws.plot_iws(tds, pseudo_obs_dim, pseudo_obs=None, kernel_bandwidths=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_samples\n",
    "plot_samples.plot_execution_time(samples, lines=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples.plot_loss_rounds(samples, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples.plot_best_samples(samples=samples, time=optim.get_rec_time(), loss=optim.loss, n=1)\n",
    "plot_samples.plot_best_samples(samples=samples, time=optim.get_rec_time(), loss=optim.loss, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_peaks\n",
    "\n",
    "xlims = [optim.get_t_rng()] + [(1.5, 2.5), (4,6), (10,14), (13.5, 17), (12, 13), (22, 25), (27, 31)]\n",
    "\n",
    "trace_peaks = plot_peaks.compare_peaks_in_traces(\n",
    "    trace_list=[loss.target, loss.rate2best_iGluSnFR_trace(samples['rate'][d_min_idx])[0]],\n",
    "    time_list=optim.loss.target_time,\n",
    "    color_list=['r', 'b'],\n",
    "    label_list=['target', 'fit'],\n",
    "    params_dict_list=[{'height_pos': 0.2, 'prom': 0.16}, {'height_pos': 0.1, 'prom': 0.05}],\n",
    "    xlims=xlims,\n",
    "    base_trace_i=0,\n",
    "    ignore_rec_times=[(15, 24)], # Ignore noisy parts.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_data_folder = os.path.join('optim_data', optim.output_folder, 'post_data')\n",
    "data_utils.make_dir(post_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_posterior = posteriors[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_sampling_dists\n",
    "\n",
    "PP = plot_sampling_dists.SamplingDistPlotter(\n",
    "    params=params, prior=delfi_optim.prior, posterior_list=posteriors,\n",
    "    lbs=prior.lower, ubs=prior.upper\n",
    ")\n",
    "\n",
    "PP.plot_sampling_dists_1D(\n",
    "    opt_x=True, params=None, plot_peak_lines=False, figsize=(12,8),\n",
    "    opt_samples=np.concatenate([tds_i[0] for tds_i in tds])[d_sort_index[:10],:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP.plot_correlation(final_posterior.S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import analyze_posterior_utils\n",
    "\n",
    "if inference_mode=='test':\n",
    "    post_n_samples = 20\n",
    "else:\n",
    "    post_n_samples = 200\n",
    "\n",
    "post_opt_params = analyze_posterior_utils.get_samples(\n",
    "    posterior=final_posterior, n_samples=post_n_samples, seed=777,\n",
    "    plot=True, prior=prior, params=params, plot_opt_x=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_rec_data_list = (inference_mode=='load_only')\n",
    "\n",
    "post_model_output_list = analyze_posterior_utils.gen_or_load_samples(\n",
    "    optim=optim, opt_params=post_opt_params, load=load_rec_data_list,\n",
    "    filename=os.path.join(post_data_folder, 'post_model_output_list.pkl'), \n",
    ")\n",
    "\n",
    "assert len(post_model_output_list) == post_n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_samples = optim.stack_model_output_list(post_model_output_list)\n",
    "all_samples = optim.stack_model_output_list([samples, post_samples])\n",
    "all_samples_sort_idx = np.argsort(all_samples['loss']['total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import print_num_failed\n",
    "post_success_list = print_num_failed.print_num_failed(post_model_output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples.plot_best_samples(post_samples, optim.get_rec_time(), loss=optim.loss, n=1)\n",
    "plot_samples.plot_best_samples(post_samples, optim.get_rec_time(), loss=optim.loss, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples.plot_loss_rounds(\n",
    "    all_samples, n_samples=np.append(n_samples, len(post_model_output_list)+n_samples[-1]), equal_x=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize posterior samples and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot successful runs.\n",
    "iGlus = np.full((len(post_success_list), optim.loss.target_time.size), np.nan)\n",
    "rates = np.full((len(post_success_list), optim.rec_ex_size), np.nan)\n",
    "Vms   = np.full((len(post_success_list), optim.rec_ex_size), np.nan)\n",
    "\n",
    "# Get successful traces.\n",
    "for idx_l, idx_r in enumerate(post_success_list):\n",
    "    iGlus[idx_l,:] = loss.rate2best_iGluSnFR_trace(post_model_output_list[idx_r]['rate'])[0]\n",
    "    rates[idx_l,:] = post_model_output_list[idx_r]['rate']\n",
    "    Vms[idx_l,:]   = post_model_output_list[idx_r]['Vm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save post data.\n",
    "data_utils.save_var(optim.get_rec_time(), os.path.join(post_data_folder, 'rec_time.pkl'))\n",
    "data_utils.save_var(iGlus,           os.path.join(post_data_folder, 'iGlus.pkl'))\n",
    "data_utils.save_var(Vms,             os.path.join(post_data_folder, 'Vms.pkl'))\n",
    "data_utils.save_var(rates,           os.path.join(post_data_folder, 'rates.pkl'))\n",
    "data_utils.save_var(final_posterior, os.path.join(post_data_folder, 'distribution.pkl'))\n",
    "data_utils.save_var([params.opt_params2sim_params(opt_params) for opt_params in post_opt_params],\n",
    "                                     os.path.join(post_data_folder, 's_params_list.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_posterior.reseed(1356)\n",
    "\n",
    "marg_n_samples = 20 if inference_mode=='test' else 200\n",
    "marginal_o_params_arr = np.empty((marg_n_samples, params.p_N))\n",
    "\n",
    "for p_idx in range(params.p_N):\n",
    "    marginal_o_params_arr[:,p_idx] = final_posterior.gen(marg_n_samples)[:,p_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP = plot_sampling_dists.SamplingDistPlotter(\n",
    "    params=params, prior=prior, posterior_list=[final_posterior],\n",
    "    lbs=np.full(params.p_N, -0.5), ubs=np.full(params.p_N, 1.5)\n",
    ")\n",
    "PP.plot_sampling_dists_1D(plot_peak_lines=False, figsize=(12,8), opt_x=True, opt_samples=marginal_o_params_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_rec_data_list = (inference_mode=='load_only')\n",
    "\n",
    "marg_data_folder = os.path.join('optim_data', optim.output_folder, 'marginal_post_data')\n",
    "data_utils.make_dir(marg_data_folder)\n",
    "\n",
    "marginal_model_output_list = analyze_posterior_utils.gen_or_load_samples(\n",
    "    optim=optim, opt_params=marginal_o_params_arr, load=load_rec_data_list,\n",
    "    filename=os.path.join(marg_data_folder, 'rec_data_list_from_marginals.pkl'), \n",
    ")\n",
    "\n",
    "assert len(marginal_model_output_list) == marg_n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best sample(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(np.arange(1,all_samples_sort_idx.size+1), all_samples['loss']['total'][all_samples_sort_idx], '.')\n",
    "plt.title(str(all_samples_sort_idx[:7]) + '\\n' + str([\"{:.3f}\".format(l) for l in all_samples['loss']['total'][all_samples_sort_idx][:7]]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model output.\n",
    "final_model_output = {}\n",
    "final_model_output['rate']        = all_samples['rate'][all_samples_sort_idx[0]]\n",
    "final_model_output['rate-off']    = all_samples['rate'][all_samples_sort_idx[0]] - all_samples['rate'][all_samples_sort_idx[0]][0]\n",
    "final_model_output['iGlu']        = loss.rate2best_iGluSnFR_trace(final_model_output['rate'])[0]\n",
    "final_model_output['Vm']          = all_samples['Vm'][all_samples_sort_idx[0]]\n",
    "final_model_output['Vm-off']      = all_samples['Vm'][all_samples_sort_idx[0]] - all_samples['Vm'][all_samples_sort_idx[0]][0] \n",
    "final_model_output['Time']        = delfi_optim.optim.get_rec_time()\n",
    "final_model_output['predur']      = predur\n",
    "final_model_output['t_rng']       = delfi_optim.optim.get_t_rng()\n",
    "final_model_output['Stimulus']    = stimulus\n",
    "final_model_output['Target']      = loss.target\n",
    "final_model_output['Time-Target'] = loss.target_time\n",
    "final_model_output['params_unit'] = params_unit.copy()\n",
    "final_model_output['params']      = {k: vs[all_samples_sort_idx[0]] for k, vs in all_samples['params'].items()}\n",
    "final_model_output['loss']        = {k: vs[all_samples_sort_idx[0]] for k, vs in all_samples['loss'].items()}\n",
    "\n",
    "data_utils.save_var(final_model_output, os.path.join(post_data_folder, 'final_model_output.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_output['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_output['params'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_rates_and_Vm\n",
    "\n",
    "plot_rates_and_Vm.plot_rates_Vms_iGlus(\n",
    "    iGlus=iGlus, rates=rates, Vms=Vms, target=optim.loss.target,\n",
    "    ts_iGlus=optim.loss.target_time, ts_rec=optim.get_rec_time(),\n",
    "    final_model_output=final_model_output,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot peak times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_peaks\n",
    "\n",
    "xlims = [optim.get_t_rng()] + [(1.5, 2.5), (4,6), (10,14), (13.5, 17), (12, 13), (22, 25), (27, 31)]\n",
    "\n",
    "trace_list = [loss.target, loss.rate2best_iGluSnFR_trace(final_model_output['rate'])[0]]\n",
    "time_list = optim.loss.target_time\n",
    "label_list = ['target', 'fit']\n",
    "params_dict_list = [{'height_pos': 0.2, 'prom': 0.16}, {'height_pos': 0.1, 'prom': 0.05}]\n",
    "\n",
    "trace_peaks = plot_peaks.compare_peaks_in_traces(\n",
    "    trace_list=trace_list,\n",
    "    time_list=time_list,\n",
    "    plot_single=False,\n",
    "    plot_hist=True,\n",
    "    plot=True,\n",
    "    params_dict_list=params_dict_list,\n",
    "    color_list=['r', 'b'],\n",
    "    label_list=label_list,\n",
    "    xlims=xlims,\n",
    "    base_trace_i=0,\n",
    "    ignore_rec_times=[(15, 24)], # Ignore noisy parts.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
