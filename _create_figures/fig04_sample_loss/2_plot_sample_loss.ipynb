{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import lines\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pythoncodepath = os.path.abspath(os.path.join('..', '..', '_pythoncode'))\n",
    "sys.path = [pythoncodepath] + sys.path\n",
    "import importhelper\n",
    "importhelper.addfolders2path(pythoncodepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_utils\n",
    "import plot_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_utils)\n",
    "plot_utils.set_rcParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_num = os.getcwd().split('/')[-1][3:5]\n",
    "print(fig_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cone_optim_folder = os.path.join('..', '..', 'step1a_optimize_cones', 'optim_data')\n",
    "cbc_optim_folder = os.path.join('..', '..', 'step2a_optimize_cbc', 'optim_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(cone_optim_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(os.listdir(cbc_optim_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell2folder = {\n",
    "    'Cone':  os.path.join(cone_optim_folder, 'optimize_cone_submission2'),\n",
    "    'OFF':  os.path.join(cbc_optim_folder, 'optimize_OFF_submission2'),\n",
    "    'ON':   os.path.join(cbc_optim_folder, 'optimize_ON_submission2'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_losses = {}\n",
    "\n",
    "for cell, folder in cell2folder.items():\n",
    "    round_losses[cell] = []\n",
    "    for file in sorted(os.listdir(os.path.join(folder, 'samples'))):\n",
    "        round_losses[cell].append(data_utils.load_var(os.path.join(folder, 'samples', file))['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get losses from posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optim_funcs\n",
    "importlib.reload(optim_funcs)\n",
    "optim = optim_funcs.EmptyOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(folder, 'post_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_losses = {}        \n",
    "for cell, folder in cell2folder.items():\n",
    "    rec_data_list = data_utils.load_var(os.path.join(folder, 'post_data', 'post_model_output_list.pkl'))\n",
    "    post_losses[cell] = optim.stack_model_output_list(rec_data_list)['loss']\n",
    "    \n",
    "post_losses_opt_cpl = {}\n",
    "for cell, folder in cell2folder.items():\n",
    "    if 'Cone' not in cell:\n",
    "        rec_data_list = data_utils.load_var(os.path.join(folder, 'post_data', 'post_model_output_list_optimize_cpl.pkl'))\n",
    "        post_losses_opt_cpl[cell] = optim.stack_model_output_list(rec_data_list)['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marg_losses = {}        \n",
    "for cell, folder in cell2folder.items():\n",
    "    rec_data_list = data_utils.load_var(os.path.join(folder, 'marginal_post_data', 'rec_data_list_from_marginals.pkl'))\n",
    "    marg_losses[cell] = optim.stack_model_output_list(rec_data_list)['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_utils.make_dir('source_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_names = list(post_losses['Cone'].keys())\n",
    "loss_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_round_losses(round_i_losses):\n",
    "    n_round = round_i_losses['total'].size \n",
    "        \n",
    "    round_data = np.full((n_round, len(loss_names)), np.nan)\n",
    "\n",
    "    for l_idx, l_name in enumerate(loss_names):\n",
    "        round_data[:, l_idx] = round_i_losses[l_name]\n",
    "        \n",
    "    return round_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_output(cell):\n",
    "\n",
    "    test_data = pd.read_csv(\n",
    "        'source_data/Sample_discrepancies_' + cell + '.csv', index_col=0)\n",
    "\n",
    "    for r in range(4):\n",
    "        for l_name, losses_i in round_losses[cell][r].items():\n",
    "            absdiff = np.abs(losses_i[~np.isnan(losses_i)]\n",
    "                             - test_data.loc['Round_' + str(r+1)][l_name].values[~np.isnan(losses_i)])\n",
    "            assert np.all(absdiff < 1e-3), np.max(absdiff)\n",
    "\n",
    "    for l_name, losses_i in post_losses[cell].items():\n",
    "        assert np.all(np.abs(losses_i[~np.isnan(losses_i)]\n",
    "                             - test_data.loc['Posterior'][l_name].values[~np.isnan(losses_i)]) < 1e-4)\n",
    "\n",
    "    for l_name, losses_i in marg_losses[cell].items():\n",
    "        assert np.all(np.abs(losses_i[~np.isnan(losses_i)]\n",
    "                             - test_data.loc['Marginals'][l_name].values[~np.isnan(losses_i)]) < 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell, round_losses_cell in round_losses.items():\n",
    "    \n",
    "    cell_data = np.full((0, len(loss_names)), np.nan)\n",
    "    \n",
    "    cell_data_rows = np.full((0), \"Col names\")\n",
    "    \n",
    "    for r_idx, round_i_losses in enumerate(round_losses_cell):\n",
    "        round_data = get_round_losses(round_i_losses)\n",
    "        cell_data = np.vstack([cell_data, round_data])\n",
    "        cell_data_rows = np.concatenate([cell_data_rows, np.full((round_data.shape[0]), \"Round_\"+str(r_idx+1))])\n",
    "        \n",
    "    round_data = get_round_losses(post_losses[cell])\n",
    "    cell_data = np.vstack([cell_data, round_data])\n",
    "    cell_data_rows = np.concatenate([cell_data_rows, np.full((round_data.shape[0]), \"Posterior\")])\n",
    "    \n",
    "    round_data = get_round_losses(marg_losses[cell])\n",
    "    cell_data = np.vstack([cell_data, round_data])\n",
    "    cell_data_rows = np.concatenate([cell_data_rows, np.full((round_data.shape[0]), \"Marginals\")])\n",
    "    \n",
    "    pd.DataFrame(cell_data, columns=loss_names, index=cell_data_rows).to_csv(\n",
    "        'source_data/Sample_discrepancies_' + cell + '.csv', float_format=\"%.6f\")\n",
    "    \n",
    "    #### TEST ####\n",
    "    check_output(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create text output\n",
    "\n",
    "\n",
    "Summarize mean, median, std and perncetile as latex commands for paper text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "text_data = []\n",
    "\n",
    "text_data.append('%' + str(datetime.now()) + '\\n')\n",
    "\n",
    "for cell, post_losses_cell in post_losses.items():\n",
    "    \n",
    "    print('\\n', cell)\n",
    "    if not np.all(np.isfinite(post_losses_cell['total'])):\n",
    "        print(np.sum(~np.isfinite(post_losses_cell['total'])), ' post samples are nans')\n",
    "    if not np.all(np.isfinite(marg_losses[cell]['total'])):\n",
    "        print(np.sum(~np.isfinite(marg_losses[cell]['total'])), ' marg samples are nans')\n",
    "    \n",
    "    for loss_key, post_losses_key in post_losses_cell.items():\n",
    "        marg_losses_key = marg_losses[cell][loss_key]\n",
    "        \n",
    "        marg_losses_key = np.abs(marg_losses_key.copy())\n",
    "        post_losses_key = np.abs(post_losses_key.copy())\n",
    "        \n",
    "        # Posterior.\n",
    "        prefix = \"\\\\newcommand\\\\postLoss\" + cell + loss_key.replace('_', '')\n",
    "        \n",
    "        text_data.append(prefix + \"Mean{\"   + \"{:.2f}\".format(np.nanmean(post_losses_key))   + \"}\\n\")\n",
    "        text_data.append(prefix + \"Median{\" + \"{:.2f}\".format(np.nanmedian(post_losses_key)) + \"}\\n\")\n",
    "        text_data.append(prefix + \"Std{\"    + \"{:.2f}\".format(np.nanstd(post_losses_key))    + \"}\\n\")\n",
    "        text_data.append(prefix + \"qNiFi{\"  + \"{:.2f}\".format(np.nanpercentile(post_losses_key, q=95)) + \"}\\n\")\n",
    "        \n",
    "        if np.median(post_losses_key) > 0.0 and loss_key not in ['total', 'iGluSnFR']:\n",
    "            print(loss_key.ljust(20), 'has non-zero median for cell\\t', cell)\n",
    "        \n",
    "        # Marginal posterior.\n",
    "        prefix = \"\\\\newcommand\\\\margPostLoss\" + cell + loss_key.replace('_', '')\n",
    "\n",
    "        text_data.append(prefix + \"Mean{\"   + \"{:.2f}\".format(np.nanmean(marg_losses_key))   + \"}\\n\")\n",
    "        text_data.append(prefix + \"Median{\" + \"{:.2f}\".format(np.nanmedian(marg_losses_key)) + \"}\\n\")\n",
    "        text_data.append(prefix + \"Std{\"    + \"{:.2f}\".format(np.nanstd(marg_losses_key))    + \"}\\n\")\n",
    "        text_data.append(prefix + \"qNiFi{\"  + \"{:.2f}\".format(np.nanpercentile(marg_losses_key, q=95)) + \"}\\n\")\n",
    "    \n",
    "OFF_iGlu_frac = 100*np.mean(post_losses['OFF']['iGluSnFR']) / np.mean(post_losses['OFF']['total'])\n",
    "ON_iGlu_frac  = 100*np.mean(post_losses['ON']['iGluSnFR'])  / np.mean(post_losses['ON']['total'])\n",
    "\n",
    "text_data.append(\"\\\\newcommand\\\\postLossIGluFracOFF{\" + \"{:.0f}\".format(OFF_iGlu_frac)+ \"}\\n\")\n",
    "text_data.append(\"\\\\newcommand\\\\postLossIGluFracON{\" + \"{:.0f}\".format(ON_iGlu_frac)  + \"}\\n\")\n",
    "\n",
    "text_data.append(\"\\\\newcommand\\\\postLossFracBetterPostThanMargOFF{\" + \"{:.0f}\".format(OFF_iGlu_frac)+ \"}\\n\")\n",
    "text_data.append(\"\\\\newcommand\\\\postLossFracBetterPostThanMargON{\" + \"{:.0f}\".format(ON_iGlu_frac)  + \"}\\n\")\n",
    "\n",
    "data_utils.make_dir('text_data')\n",
    "with open('text_data/post_loss_data.tex', 'w') as f:\n",
    "    f.writelines(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell, round_losses_i in round_losses.items():\n",
    "    print(cell)\n",
    "    for round_loss in round_losses_i:\n",
    "        print(np.sum(np.isnan(round_loss['total'])), end='\\t')\n",
    "        \n",
    "    print('post:', np.sum(np.isnan(post_losses[cell]['total'])), end='\\t')\n",
    "    print('marg:', np.sum(np.isnan(marg_losses[cell]['total'])), end='\\t')\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell, cell_post_losses in post_losses.items():\n",
    "    print(cell)\n",
    "    for loss_key, losses in cell_post_losses.items():\n",
    "        print(loss_key.ljust(20), f\"{np.mean(np.abs(losses)):.4f}\")\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss of final model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell2final_model_outputs = {\n",
    "    cell: data_utils.load_var(os.path.join(folder, 'post_data', 'final_model_output.pkl'))\n",
    "        for cell, folder in cell2folder.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell, final_model_output in cell2final_model_outputs.items():\n",
    "    print(cell)\n",
    "    for loss_key, loss_value in final_model_output['loss'].items():\n",
    "        if loss_value != 0.0:\n",
    "            print(loss_key.ljust(20), f\"{loss_value:.6f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "text_output = []\n",
    "text_output.append('%' + str(datetime.now()) + '\\n')\n",
    "for cell, final_model_output in cell2final_model_outputs.items():\n",
    "    total_loss = final_model_output['loss']['total']\n",
    "    text_output.append(\"\\\\newcommand\\\\optimized\" + cell + \"TotalLoss{\" + \"{:.2f}\".format(total_loss) + \"}\\n\")\n",
    "\n",
    "with open('text_data/optimizedCellsLoss.tex', 'w') as f:\n",
    "    f.writelines(text_output)\n",
    "    \n",
    "text_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell, cell_post_losses_opt_cpl in post_losses_opt_cpl.items():\n",
    "    print(cell)\n",
    "    cell_post_losses = post_losses[cell]\n",
    "    \n",
    "    print(100*np.sum(cell_post_losses['total'] < cell_post_losses_opt_cpl['total']) / cell_post_losses['total'].size)\n",
    "    \n",
    "    sort_idx = np.argsort(cell_post_losses_opt_cpl['total'])\n",
    "    \n",
    "    print(np.sum(cell_post_losses['total'][sort_idx][:40] < cell_post_losses_opt_cpl['total'][sort_idx][:40]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss over rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_round_loss(ax, round_loss, bottom, loss_min, loss_max, weight=1, squeeze=1):\n",
    "    plot_areas(ax, round_loss, bottom, weight, squeeze)\n",
    "    plot_hist(ax, round_loss, bottom, loss_min, loss_max, weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_areas(ax, round_loss, bottom, weight, squeeze):\n",
    "    \n",
    "    round_loss = round_loss.copy()\n",
    "    \n",
    "    xmin = bottom\n",
    "    xmax = bottom+round_loss.size*weight*squeeze\n",
    "    \n",
    "    ax.plot(\n",
    "        [xmin, xmax],\n",
    "        np.tile(np.nanmedian(round_loss), 2),\n",
    "        color='r', lw=0.6, alpha=1, zorder=1, clip_on=True\n",
    "    )\n",
    "\n",
    "    ax.fill_between(\n",
    "        [xmin, xmax],\n",
    "        np.tile(np.nanpercentile(round_loss,  5), 2),\n",
    "        np.tile(np.nanpercentile(round_loss, 95), 2),\n",
    "        alpha=0.2, label='_', color='k', lw=0,\n",
    "    )         \n",
    "\n",
    "    ax.fill_between(\n",
    "        [xmin, xmax],\n",
    "        np.tile(np.nanpercentile(round_loss, 25), 2),\n",
    "        np.tile(np.nanpercentile(round_loss, 75), 2),\n",
    "        alpha=0.5, label='_', color='steelblue', lw=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 31\n",
    "\n",
    "def plot_hist(ax, round_loss, bottom, loss_min, loss_max, weight=1):\n",
    "    \n",
    "    round_loss = round_loss.copy()\n",
    "    \n",
    "    assert isinstance(loss_max, (float,int))\n",
    "    assert isinstance(round_loss, (np.ndarray, list)), type(round_loss)\n",
    "    \n",
    "    round_loss[np.isnan(round_loss)] = loss_max\n",
    "    \n",
    "    ax.hist(\n",
    "        round_loss, orientation=\"horizontal\", bottom=bottom,\n",
    "        bins=np.linspace(np.min(round_loss),loss_max+0.5*loss_max/n_bins,n_bins-1), \n",
    "        zorder=1, alpha=0.5, facecolor='k', range=(0, loss_max), align='mid', lw=0.0,\n",
    "        weights=np.ones(round_loss.size)*weight\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rounds = 4\n",
    "n_samples_per_round = 2000\n",
    "\n",
    "plot_cols = {\n",
    "    'total': {'min': 0, 'max': 7, 'title': r'$\\delta_{total}$'},\n",
    "    'iGluSnFR': {'min': 0, 'max': 1, 'title': r'$\\delta_{iGluSnFR}$'},\n",
    "}\n",
    "\n",
    "def plot_loss(axs, squeeze_areas=1.0):\n",
    "    \n",
    "    # Make axis nice.\n",
    "    for ax, (loss_key, plot_params) in zip(axs[0,:], plot_cols.items()):\n",
    "        ax.set_title(plot_params['title'])\n",
    "\n",
    "    for ax_row in axs:\n",
    "        for ax, (loss_key, plot_params) in zip(ax_row, plot_cols.items()):\n",
    "            ax.set_ylim(plot_params['min'], plot_params['max'])\n",
    "            ax.set_yticks([plot_params['min'], plot_params['max']])\n",
    "        ax_row[0].set_ylabel('Discrepancy')\n",
    "\n",
    "    for ax in axs.flatten():\n",
    "        xticks = [n_samples_per_round*i for i in range(n_rounds)]\n",
    "        ax.set_xticks([n_samples_per_round*i for i in range(n_rounds+2)])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_xlim(0, (2+n_rounds)*n_samples_per_round)\n",
    "\n",
    "        ax.spines[\"left\"].set_position((\"axes\", -0.03))\n",
    "        ax.spines['bottom'].set_bounds(0, n_rounds*n_samples_per_round)\n",
    "\n",
    "    for ax in axs[-1,:]:\n",
    "        ax.set_xticklabels(list(np.arange(n_rounds)+1) + [\"p.\", \"m.\"])\n",
    "        ax.set_xlabel(r'Round')\n",
    "        \n",
    "        \n",
    "    # Plot data.\n",
    "    for ax_row, (cell, round_losses_cell) in zip(axs, round_losses.items()):\n",
    "        bottom = 0\n",
    "\n",
    "        # Plot round loss.\n",
    "        for round_loss in round_losses_cell:\n",
    "            for ax, (loss_key, plot_params) in zip(ax_row, plot_cols.items()):\n",
    "                assert n_samples_per_round == round_loss[loss_key].size\n",
    "                plot_round_loss(\n",
    "                    ax, round_loss[loss_key], bottom,\n",
    "                    loss_min=plot_params['min'], loss_max=plot_params['max'],\n",
    "                    squeeze=squeeze_areas,\n",
    "                )\n",
    "                ax.axvline(bottom, c='k', linestyle='-', zorder=10, alpha=0.4, linewidth=1, clip_on=False)\n",
    "            bottom += n_samples_per_round\n",
    "\n",
    "        # Plot post loss.\n",
    "        for ax, (loss_key, plot_params) in zip(ax_row, plot_cols.items()):\n",
    "            w = float(n_samples_per_round / post_losses[cell][loss_key].size)\n",
    "            plot_round_loss(\n",
    "                ax, post_losses[cell][loss_key], bottom,\n",
    "                loss_min=plot_params['min'], loss_max=plot_params['max'], weight=w,\n",
    "                squeeze=squeeze_areas,\n",
    "            )\n",
    "            ax.axvline(bottom, c='k', linestyle='--', zorder=10, alpha=0.4, linewidth=1)\n",
    "        bottom += n_samples_per_round\n",
    "\n",
    "        # Plot marg loss.\n",
    "        for ax, (loss_key, plot_params) in zip(ax_row, plot_cols.items()):\n",
    "            w = float(n_samples_per_round / marg_losses[cell][loss_key].size)\n",
    "            plot_round_loss(\n",
    "                ax, marg_losses[cell][loss_key], bottom,\n",
    "                loss_min=plot_params['min'], loss_max=plot_params['max'], weight=w,\n",
    "                squeeze=squeeze_areas,\n",
    "            )\n",
    "            ax.axvline(bottom, c='darkblue', linestyle='-', zorder=10, alpha=0.4, linewidth=1)\n",
    "        bottom += n_samples_per_round\n",
    "\n",
    "\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,2,figsize=(12,10), sharey=False, sharex=True, squeeze=False)\n",
    "plot_loss(axs, squeeze_areas=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_iGluSnFR_losses = data_utils.load_var('source_data/all_iGluSnFR_losses.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming = {\n",
    "    'OFF model_output': 'Model',\n",
    "    'OFF strychnine': 'Target',\n",
    "    'OFF no_drug': 'No drug',\n",
    "    'OFF similar_strychnine': 'BC4',\n",
    "    'ON model_output': 'Model',\n",
    "    'ON strychnine': 'Target',\n",
    "    'ON no_drug': 'No drug',\n",
    "    'ON similar_strychnine': 'BC7',   \n",
    "}\n",
    "\n",
    "annotatations = [renaming[col] for col in all_iGluSnFR_losses.columns]\n",
    "\n",
    "for i in np.arange(0,4):\n",
    "    'OFF' in all_iGluSnFR_losses.columns[0]\n",
    "for i in np.arange(4,8):\n",
    "    'ON' in all_iGluSnFR_losses.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patheffects as path_effects\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def plot_comparison(ax):\n",
    "    \n",
    "    im = ax.imshow(all_iGluSnFR_losses.values, cmap='Blues', vmin=0, vmax=0.6)\n",
    "    \n",
    "    ax.set_xticks(np.arange(len(annotatations)))\n",
    "    ax.set_xticklabels(annotatations, rotation=90)\n",
    "    ax.set_yticks(np.arange(len(annotatations)))\n",
    "    ax.set_yticklabels(annotatations, rotation=0)\n",
    "    \n",
    "    ax.set_xlim(ax.get_xlim())\n",
    "    ax.set_ylim(ax.get_ylim())\n",
    "    \n",
    "    ax.tick_params(length=0)\n",
    "    \n",
    "    ax.text(-3, len(annotatations)/4 - 0.5,   'OFF', ha='right', va='center', rotation=90)\n",
    "    ax.text(-3, len(annotatations)*3/4 - 0.5, 'ON',  ha='right', va='center', rotation=90)\n",
    "    \n",
    "    ax.plot([-2.9, -2.9], [-0.4,3.4], clip_on=False, c='dimgray')\n",
    "    ax.plot([-2.9, -2.9], [3.6, 7.4], clip_on=False, c='dimgray')\n",
    "    \n",
    "    ax.text(len(annotatations)/4 - 0.5,   10.2,  'OFF', ha='center', va='top')\n",
    "    ax.text(len(annotatations)*3/4 - 0.5, 10.2,  'ON', ha='center',  va='top')\n",
    "    \n",
    "    ax.plot([-0.4,3.4], [10., 10], clip_on=False, c='dimgray')\n",
    "    ax.plot([3.6, 7.4], [10., 10], clip_on=False, c='dimgray')\n",
    "    \n",
    "    for idx1, key1 in enumerate(all_iGluSnFR_losses.index):\n",
    "        for idx2, key2 in enumerate(all_iGluSnFR_losses.columns):\n",
    "            color = 'w'\n",
    "            \n",
    "            if all_iGluSnFR_losses.loc[key1, key2] >= 0.999:\n",
    "                st = \"1\"\n",
    "            elif all_iGluSnFR_losses.loc[key1, key2] < 1e-4:\n",
    "                st = \"0\"\n",
    "            else:\n",
    "                st = \"{:.2f}\".format(all_iGluSnFR_losses.loc[key1, key2])[1:]\n",
    "    \n",
    "            text = ax.text(\n",
    "                idx1, idx2, st, ha=\"center\", va=\"center\", color=color,\n",
    "                path_effects=[path_effects.Stroke(linewidth=1.5, foreground='k'),  path_effects.Normal()],\n",
    "                fontsize=7\n",
    "            )\n",
    "    \n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    \n",
    "    cb = plt.colorbar(im, ax=ax, cax=cax)\n",
    "    \n",
    "    cb.set_ticks([0.0, 0.2, 0.4, 0.6])\n",
    "    cb.set_ticklabels([0.0, 0.2, 0.4, ] + [\">0.6\"])\n",
    "    cb.set_label(r'$\\delta_{iGluSnFR}$', rotation=90, ha='center', labelpad=-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(ax=plt.subplot(111))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbnx = 3\n",
    "sbny = 3\n",
    "\n",
    "fig, axs = plt.subplots(ncols=sbnx, nrows=sbny, figsize=(5.6,2.5), gridspec_kw=dict(width_ratios=[1,1,2.]))\n",
    "#fig, axs = plt.subplots(ncols=sbnx, nrows=sbny, figsize=(7.4,2.3), gridspec_kw=dict(width_ratios=[1,1,2.3]))\n",
    "\n",
    "gs = axs[0, 0].get_gridspec()\n",
    "for ax in axs[:, 2]: ax.remove()\n",
    "axbig = fig.add_subplot(gs[:, 2])\n",
    "\n",
    "for ax, ABC in zip(axs[:,0], ['A', 'B', 'C']):\n",
    "    ax.set_title(ABC+'          ', loc='left', fontweight=\"bold\", ha='right')\n",
    "axbig.set_title('D'+'            ', loc='left', fontweight=\"bold\", ha='right')\n",
    "\n",
    "plot_loss(axs[:,:2], squeeze_areas=0.8)\n",
    "\n",
    "plt.tight_layout(w_pad=-4, h_pad=0)\n",
    "\n",
    "plot_comparison(ax=axbig)\n",
    "box = np.asarray(axbig.get_position().bounds)\n",
    "box[0] += 0.08\n",
    "box[2] -= 0.08\n",
    "\n",
    "box[1] += 0.14\n",
    "box[3] -= 0.14\n",
    "axbig.set_position(box)\n",
    "\n",
    "axbig.spines['top'].set_visible(True)\n",
    "axbig.spines['right'].set_visible(True)\n",
    "\n",
    "axbig.set_position(np.array(axbig.get_position().bounds) + [-0.005, 0,0,0])\n",
    "\n",
    "plt.savefig(f'../_figures/fig{fig_num}_sample_loss.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
